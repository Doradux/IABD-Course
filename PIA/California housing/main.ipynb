{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california_housing = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.23        4.526  \n",
       "1        -122.22        3.585  \n",
       "2        -122.24        3.521  \n",
       "3        -122.25        3.413  \n",
       "4        -122.25        3.422  \n",
       "...          ...          ...  \n",
       "20635    -121.09        0.781  \n",
       "20636    -121.21        0.771  \n",
       "20637    -121.22        0.923  \n",
       "20638    -121.32        0.847  \n",
       "20639    -121.24        0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([california_housing.data, california_housing.target], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compruebo valores nulos de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc         0\n",
       "HouseAge       0\n",
       "AveRooms       0\n",
       "AveBedrms      0\n",
       "Population     0\n",
       "AveOccup       0\n",
       "Latitude       0\n",
       "Longitude      0\n",
       "MedHouseVal    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['MedHouseVal'], axis=1)\n",
    "y = df['MedHouseVal']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Especificidad(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"especificidad\", **kwargs):\n",
    "        super(Especificidad, self).__init__(name=name, **kwargs)\n",
    "        self.true_negatives = self.add_weight(name=\"tn\", initializer=\"zeros\")\n",
    "        self.false_positives = self.add_weight(name=\"fp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.round(y_pred)\n",
    "        tn = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_positives.assign_add(fp)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_negatives / (self.true_negatives + self.false_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_negatives.assign(0.0)\n",
    "        self.false_positives.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sensibilidad(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"sensibilidad\", **kwargs):\n",
    "        super(Sensibilidad, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n",
    "        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convertir a float32 para evitar conflictos de tipo\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.round(y_pred)  # Redondeamos para obtener las predicciones binarias\n",
    "        tp = tf.reduce_sum(y_true * y_pred)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2601 - mean_absolute_error: 0.3555 - val_loss: 0.2635 - val_mean_absolute_error: 0.3411\n",
      "Epoch 2/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2644 - mean_absolute_error: 0.3581 - val_loss: 0.2617 - val_mean_absolute_error: 0.3474\n",
      "Epoch 3/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2645 - mean_absolute_error: 0.3563 - val_loss: 0.2747 - val_mean_absolute_error: 0.3583\n",
      "Epoch 4/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2593 - mean_absolute_error: 0.3546 - val_loss: 0.2667 - val_mean_absolute_error: 0.3498\n",
      "Epoch 5/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2604 - mean_absolute_error: 0.3563 - val_loss: 0.2744 - val_mean_absolute_error: 0.3572\n",
      "Epoch 6/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2622 - mean_absolute_error: 0.3557 - val_loss: 0.2713 - val_mean_absolute_error: 0.3512\n",
      "Epoch 7/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2662 - mean_absolute_error: 0.3557 - val_loss: 0.2665 - val_mean_absolute_error: 0.3459\n",
      "Epoch 8/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2637 - mean_absolute_error: 0.3570 - val_loss: 0.2696 - val_mean_absolute_error: 0.3595\n",
      "Epoch 9/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2610 - mean_absolute_error: 0.3583 - val_loss: 0.2645 - val_mean_absolute_error: 0.3448\n",
      "Epoch 10/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2693 - mean_absolute_error: 0.3607 - val_loss: 0.2689 - val_mean_absolute_error: 0.3533\n",
      "Epoch 11/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2647 - mean_absolute_error: 0.3603 - val_loss: 0.2738 - val_mean_absolute_error: 0.3590\n",
      "Epoch 12/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2581 - mean_absolute_error: 0.3555 - val_loss: 0.2643 - val_mean_absolute_error: 0.3423\n",
      "Epoch 13/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2543 - mean_absolute_error: 0.3515 - val_loss: 0.2606 - val_mean_absolute_error: 0.3416\n",
      "Epoch 14/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2695 - mean_absolute_error: 0.3632 - val_loss: 0.2650 - val_mean_absolute_error: 0.3525\n",
      "Epoch 15/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2659 - mean_absolute_error: 0.3564 - val_loss: 0.2728 - val_mean_absolute_error: 0.3544\n",
      "Epoch 16/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2637 - mean_absolute_error: 0.3581 - val_loss: 0.2796 - val_mean_absolute_error: 0.3604\n",
      "Epoch 17/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2678 - mean_absolute_error: 0.3606 - val_loss: 0.2677 - val_mean_absolute_error: 0.3551\n",
      "Epoch 18/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2611 - mean_absolute_error: 0.3573 - val_loss: 0.2702 - val_mean_absolute_error: 0.3595\n",
      "Epoch 19/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2596 - mean_absolute_error: 0.3524 - val_loss: 0.2660 - val_mean_absolute_error: 0.3526\n",
      "Epoch 20/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2647 - mean_absolute_error: 0.3582 - val_loss: 0.2603 - val_mean_absolute_error: 0.3393\n",
      "Epoch 21/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2620 - mean_absolute_error: 0.3552 - val_loss: 0.2585 - val_mean_absolute_error: 0.3437\n",
      "Epoch 22/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2654 - mean_absolute_error: 0.3550 - val_loss: 0.2617 - val_mean_absolute_error: 0.3518\n",
      "Epoch 23/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2619 - mean_absolute_error: 0.3590 - val_loss: 0.2675 - val_mean_absolute_error: 0.3481\n",
      "Epoch 24/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2613 - mean_absolute_error: 0.3560 - val_loss: 0.2632 - val_mean_absolute_error: 0.3466\n",
      "Epoch 25/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2637 - mean_absolute_error: 0.3592 - val_loss: 0.2637 - val_mean_absolute_error: 0.3578\n",
      "Epoch 26/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2690 - mean_absolute_error: 0.3591 - val_loss: 0.2672 - val_mean_absolute_error: 0.3526\n",
      "Epoch 27/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2584 - mean_absolute_error: 0.3520 - val_loss: 0.2711 - val_mean_absolute_error: 0.3580\n",
      "Epoch 28/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2627 - mean_absolute_error: 0.3554 - val_loss: 0.2729 - val_mean_absolute_error: 0.3537\n",
      "Epoch 29/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2577 - mean_absolute_error: 0.3521 - val_loss: 0.2736 - val_mean_absolute_error: 0.3531\n",
      "Epoch 30/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2681 - mean_absolute_error: 0.3596 - val_loss: 0.2721 - val_mean_absolute_error: 0.3520\n",
      "Epoch 31/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2553 - mean_absolute_error: 0.3542 - val_loss: 0.2609 - val_mean_absolute_error: 0.3484\n",
      "Epoch 32/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2644 - mean_absolute_error: 0.3595 - val_loss: 0.2507 - val_mean_absolute_error: 0.3374\n",
      "Epoch 33/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2568 - mean_absolute_error: 0.3536 - val_loss: 0.2666 - val_mean_absolute_error: 0.3532\n",
      "Epoch 34/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2658 - mean_absolute_error: 0.3583 - val_loss: 0.2593 - val_mean_absolute_error: 0.3444\n",
      "Epoch 35/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2594 - mean_absolute_error: 0.3561 - val_loss: 0.2580 - val_mean_absolute_error: 0.3430\n",
      "Epoch 36/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2617 - mean_absolute_error: 0.3569 - val_loss: 0.2629 - val_mean_absolute_error: 0.3476\n",
      "Epoch 37/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2702 - mean_absolute_error: 0.3613 - val_loss: 0.2623 - val_mean_absolute_error: 0.3417\n",
      "Epoch 38/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2721 - mean_absolute_error: 0.3629 - val_loss: 0.2608 - val_mean_absolute_error: 0.3477\n",
      "Epoch 39/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2637 - mean_absolute_error: 0.3544 - val_loss: 0.2529 - val_mean_absolute_error: 0.3386\n",
      "Epoch 40/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2640 - mean_absolute_error: 0.3546 - val_loss: 0.2701 - val_mean_absolute_error: 0.3511\n",
      "Epoch 41/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2730 - mean_absolute_error: 0.3608 - val_loss: 0.2620 - val_mean_absolute_error: 0.3458\n",
      "Epoch 42/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2645 - mean_absolute_error: 0.3580 - val_loss: 0.2543 - val_mean_absolute_error: 0.3398\n",
      "Epoch 43/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2616 - mean_absolute_error: 0.3562 - val_loss: 0.2566 - val_mean_absolute_error: 0.3446\n",
      "Epoch 44/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2607 - mean_absolute_error: 0.3545 - val_loss: 0.2593 - val_mean_absolute_error: 0.3434\n",
      "Epoch 45/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2546 - mean_absolute_error: 0.3512 - val_loss: 0.2708 - val_mean_absolute_error: 0.3498\n",
      "Epoch 46/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2598 - mean_absolute_error: 0.3548 - val_loss: 0.2577 - val_mean_absolute_error: 0.3400\n",
      "Epoch 47/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2603 - mean_absolute_error: 0.3534 - val_loss: 0.2672 - val_mean_absolute_error: 0.3501\n",
      "Epoch 48/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2601 - mean_absolute_error: 0.3546 - val_loss: 0.2663 - val_mean_absolute_error: 0.3462\n",
      "Epoch 49/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2666 - mean_absolute_error: 0.3592 - val_loss: 0.2574 - val_mean_absolute_error: 0.3397\n",
      "Epoch 50/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2578 - mean_absolute_error: 0.3521 - val_loss: 0.2591 - val_mean_absolute_error: 0.3412\n",
      "Epoch 51/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2606 - mean_absolute_error: 0.3557 - val_loss: 0.2698 - val_mean_absolute_error: 0.3558\n",
      "Epoch 52/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2613 - mean_absolute_error: 0.3541 - val_loss: 0.2812 - val_mean_absolute_error: 0.3637\n",
      "Epoch 53/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2603 - mean_absolute_error: 0.3577 - val_loss: 0.2710 - val_mean_absolute_error: 0.3547\n",
      "Epoch 54/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2496 - mean_absolute_error: 0.3485 - val_loss: 0.2582 - val_mean_absolute_error: 0.3447\n",
      "Epoch 55/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2605 - mean_absolute_error: 0.3559 - val_loss: 0.2643 - val_mean_absolute_error: 0.3526\n",
      "Epoch 56/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2626 - mean_absolute_error: 0.3550 - val_loss: 0.2573 - val_mean_absolute_error: 0.3384\n",
      "Epoch 57/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2635 - mean_absolute_error: 0.3562 - val_loss: 0.2642 - val_mean_absolute_error: 0.3508\n",
      "Epoch 58/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2563 - mean_absolute_error: 0.3508 - val_loss: 0.2713 - val_mean_absolute_error: 0.3584\n",
      "Epoch 59/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2686 - mean_absolute_error: 0.3575 - val_loss: 0.2814 - val_mean_absolute_error: 0.3565\n",
      "Epoch 60/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2561 - mean_absolute_error: 0.3513 - val_loss: 0.2759 - val_mean_absolute_error: 0.3536\n",
      "Epoch 61/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2612 - mean_absolute_error: 0.3524 - val_loss: 0.2663 - val_mean_absolute_error: 0.3494\n",
      "Epoch 62/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2614 - mean_absolute_error: 0.3547 - val_loss: 0.2694 - val_mean_absolute_error: 0.3479\n",
      "Epoch 63/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2572 - mean_absolute_error: 0.3560 - val_loss: 0.2630 - val_mean_absolute_error: 0.3449\n",
      "Epoch 64/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2636 - mean_absolute_error: 0.3569 - val_loss: 0.2679 - val_mean_absolute_error: 0.3534\n",
      "Epoch 65/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2517 - mean_absolute_error: 0.3506 - val_loss: 0.2622 - val_mean_absolute_error: 0.3429\n",
      "Epoch 66/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2605 - mean_absolute_error: 0.3532 - val_loss: 0.2685 - val_mean_absolute_error: 0.3548\n",
      "Epoch 67/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2601 - mean_absolute_error: 0.3561 - val_loss: 0.2702 - val_mean_absolute_error: 0.3547\n",
      "Epoch 68/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2652 - mean_absolute_error: 0.3572 - val_loss: 0.2554 - val_mean_absolute_error: 0.3483\n",
      "Epoch 69/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2642 - mean_absolute_error: 0.3552 - val_loss: 0.2778 - val_mean_absolute_error: 0.3580\n",
      "Epoch 70/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2624 - mean_absolute_error: 0.3538 - val_loss: 0.2671 - val_mean_absolute_error: 0.3549\n",
      "Epoch 71/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2560 - mean_absolute_error: 0.3537 - val_loss: 0.2620 - val_mean_absolute_error: 0.3446\n",
      "Epoch 72/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2588 - mean_absolute_error: 0.3531 - val_loss: 0.2656 - val_mean_absolute_error: 0.3502\n",
      "Epoch 73/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2707 - mean_absolute_error: 0.3615 - val_loss: 0.2676 - val_mean_absolute_error: 0.3533\n",
      "Epoch 74/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2578 - mean_absolute_error: 0.3542 - val_loss: 0.2733 - val_mean_absolute_error: 0.3541\n",
      "Epoch 75/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2582 - mean_absolute_error: 0.3557 - val_loss: 0.2735 - val_mean_absolute_error: 0.3585\n",
      "Epoch 76/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2494 - mean_absolute_error: 0.3472 - val_loss: 0.2530 - val_mean_absolute_error: 0.3456\n",
      "Epoch 77/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2712 - mean_absolute_error: 0.3612 - val_loss: 0.2595 - val_mean_absolute_error: 0.3414\n",
      "Epoch 78/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2449 - mean_absolute_error: 0.3458 - val_loss: 0.2528 - val_mean_absolute_error: 0.3404\n",
      "Epoch 79/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2559 - mean_absolute_error: 0.3496 - val_loss: 0.2644 - val_mean_absolute_error: 0.3567\n",
      "Epoch 80/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2545 - mean_absolute_error: 0.3531 - val_loss: 0.2594 - val_mean_absolute_error: 0.3485\n",
      "Epoch 81/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2556 - mean_absolute_error: 0.3509 - val_loss: 0.2752 - val_mean_absolute_error: 0.3532\n",
      "Epoch 82/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2601 - mean_absolute_error: 0.3535 - val_loss: 0.2779 - val_mean_absolute_error: 0.3580\n",
      "Epoch 83/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2599 - mean_absolute_error: 0.3521 - val_loss: 0.2666 - val_mean_absolute_error: 0.3496\n",
      "Epoch 84/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2636 - mean_absolute_error: 0.3550 - val_loss: 0.2641 - val_mean_absolute_error: 0.3487\n",
      "Epoch 85/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2609 - mean_absolute_error: 0.3544 - val_loss: 0.2603 - val_mean_absolute_error: 0.3390\n",
      "Epoch 86/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2558 - mean_absolute_error: 0.3495 - val_loss: 0.2735 - val_mean_absolute_error: 0.3575\n",
      "Epoch 87/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2619 - mean_absolute_error: 0.3565 - val_loss: 0.2498 - val_mean_absolute_error: 0.3405\n",
      "Epoch 88/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2579 - mean_absolute_error: 0.3552 - val_loss: 0.2649 - val_mean_absolute_error: 0.3454\n",
      "Epoch 89/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2565 - mean_absolute_error: 0.3510 - val_loss: 0.2623 - val_mean_absolute_error: 0.3478\n",
      "Epoch 90/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2632 - mean_absolute_error: 0.3561 - val_loss: 0.2603 - val_mean_absolute_error: 0.3417\n",
      "Epoch 91/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2541 - mean_absolute_error: 0.3519 - val_loss: 0.2664 - val_mean_absolute_error: 0.3510\n",
      "Epoch 92/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2620 - mean_absolute_error: 0.3573 - val_loss: 0.2773 - val_mean_absolute_error: 0.3562\n",
      "Epoch 93/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2440 - mean_absolute_error: 0.3482 - val_loss: 0.2694 - val_mean_absolute_error: 0.3630\n",
      "Epoch 94/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2471 - mean_absolute_error: 0.3476 - val_loss: 0.2707 - val_mean_absolute_error: 0.3501\n",
      "Epoch 95/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2609 - mean_absolute_error: 0.3545 - val_loss: 0.2653 - val_mean_absolute_error: 0.3483\n",
      "Epoch 96/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2549 - mean_absolute_error: 0.3514 - val_loss: 0.2680 - val_mean_absolute_error: 0.3503\n",
      "Epoch 97/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2627 - mean_absolute_error: 0.3578 - val_loss: 0.2529 - val_mean_absolute_error: 0.3391\n",
      "Epoch 98/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2574 - mean_absolute_error: 0.3544 - val_loss: 0.2565 - val_mean_absolute_error: 0.3455\n",
      "Epoch 99/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2533 - mean_absolute_error: 0.3510 - val_loss: 0.2631 - val_mean_absolute_error: 0.3487\n",
      "Epoch 100/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2525 - mean_absolute_error: 0.3529 - val_loss: 0.2547 - val_mean_absolute_error: 0.3394\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor MSE: 0.2498\n",
      "Mejor MAE: 0.3374\n"
     ]
    }
   ],
   "source": [
    "min_mse = min(history.history['val_loss'])  # MSE de validación\n",
    "min_mae = min(history.history['val_mean_absolute_error'])  # MAE de validación\n",
    "\n",
    "print(f\"Mejor MSE: {min_mse:.4f}\")\n",
    "print(f\"Mejor MAE: {min_mae:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

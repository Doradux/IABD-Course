{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "# Keras (dentro de TensorFlow)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Configuración\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matriz_confusion(axes,TP=0,TN=0,FP=0,FN=0,fontsize=15,vpp=None,vpn=None,sensibilidad=None,especificidad=None,f1_score=None,mcc=None,auc=None,prevalencia=None):\n",
    "    success_color=matplotlib.colors.to_rgb('#9EE548')\n",
    "    failure_color=matplotlib.colors.to_rgb(\"#C32240\")\n",
    "    blanco_color=matplotlib.colors.to_rgb(\"#FFFFFF\")\n",
    "\n",
    "\n",
    "    if ((vpp is not None) |\n",
    "        (vpn is not None) |\n",
    "        (sensibilidad is not None) |\n",
    "        (especificidad is not None) |\n",
    "        (prevalencia is not None) |\n",
    "        (f1_score is not None) |\n",
    "        (mcc is not None) |\n",
    "        (auc is not None) ):\n",
    "        show_metrics=True\n",
    "    else:\n",
    "        show_metrics=False\n",
    "\n",
    "\n",
    "    if show_metrics==False:\n",
    "        axes.imshow([[success_color,failure_color],[failure_color,success_color]])\n",
    "    else:\n",
    "        axes.imshow([[success_color,failure_color,blanco_color],[failure_color,success_color,blanco_color],[blanco_color,blanco_color,blanco_color]])\n",
    "\n",
    "\n",
    "\n",
    "    labels = ['Positivo','Negativo']\n",
    "    xaxis = np.arange(len(labels))\n",
    "    axes.set_xticks(xaxis)\n",
    "    axes.set_yticks(xaxis)\n",
    "    axes.set_xticklabels(labels, fontsize=13, color=\"#003B80\")\n",
    "    axes.set_yticklabels(labels, fontsize=13, color=\"#003B80\")\n",
    "    axes.text(0, 0, str(TP)+\" TP\",ha=\"center\", va=\"center\", color=\"#0A2102\",fontsize=fontsize)\n",
    "    axes.text(0, 1, str(FP)+\" FP\",ha=\"center\", va=\"center\", color=\"#FAEAEA\",fontsize=fontsize)\n",
    "    axes.text(1, 0, str(FN)+\" FN\",ha=\"center\", va=\"center\", color=\"#FAEAEA\",fontsize=fontsize)\n",
    "    axes.text(1, 1, str(TN)+\" TN\",ha=\"center\", va=\"center\", color=\"#0A2102\",fontsize=fontsize)\n",
    "    axes.xaxis.tick_top()\n",
    "    axes.set_xlabel('Predicción', fontsize=fontsize, color=\"#003B80\")\n",
    "    axes.xaxis.set_label_position('top')\n",
    "    axes.set_ylabel('Realidad', fontsize=fontsize, color=\"#003B80\")\n",
    "\n",
    "\n",
    "    if show_metrics==True:\n",
    "\n",
    "\n",
    "        if (vpp is not None):\n",
    "            axes.text(0, 2, f\"Precision\\n{vpp:.2f}\",ha=\"center\", va=\"center\", color=\"#0A2102\",fontsize=fontsize-4)\n",
    "        if (vpn is not None):\n",
    "            axes.text(1, 2, f\"VPN\\n{vpn:.2f}\",ha=\"center\", va=\"center\", color=\"#0A2102\",fontsize=fontsize-4)\n",
    "        if (sensibilidad is not None):\n",
    "            axes.text(2, 0, f\"Sensibilidad\\n{sensibilidad:.2f}\",ha=\"center\", va=\"center\", color=\"#0A2102\",fontsize=fontsize-4)\n",
    "        if (especificidad is not None):\n",
    "            axes.text(2, 1, f\"Especificidad\\n{especificidad:.2f}\",ha=\"center\", va=\"center\", color=\"#0A2102\",fontsize=fontsize-4)\n",
    "\n",
    "        metricas_generales=\"\"\n",
    "        if (prevalencia is not None):\n",
    "            metricas_generales=metricas_generales+f\"Prevalencia\\n{prevalencia:.2f}\\n\"\n",
    "        if (f1_score is not None):\n",
    "            metricas_generales=metricas_generales+f\"F1-score\\n{f1_score:.2f}\\n\"\n",
    "        if (mcc is not None):\n",
    "            metricas_generales=metricas_generales+f\"MCC\\n{mcc:.2f}\\n\"\n",
    "        if (auc is not None):\n",
    "            metricas_generales=metricas_generales+f\"AUC\\n{auc:.2f}\"\n",
    "\n",
    "        axes.text(2, 2, metricas_generales,ha=\"center\", va=\"center\", color=\"#0A2102\",fontsize=fontsize-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading heart-disease-health-indicators-dataset.zip to .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/2.66M [00:00<?, ?B/s]\n",
      " 38%|███▊      | 1.00M/2.66M [00:00<00:00, 1.91MB/s]\n",
      "100%|██████████| 2.66M/2.66M [00:00<00:00, 4.60MB/s]\n",
      "100%|██████████| 2.66M/2.66M [00:00<00:00, 3.96MB/s]\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "!kaggle datasets download -d alexteboul/heart-disease-health-indicators-dataset -p . --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n",
       "0                        0.0     1.0       1.0        1.0  40.0     1.0   \n",
       "1                        0.0     0.0       0.0        0.0  25.0     1.0   \n",
       "2                        0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "3                        0.0     1.0       0.0        1.0  27.0     0.0   \n",
       "4                        0.0     1.0       1.0        1.0  24.0     0.0   \n",
       "...                      ...     ...       ...        ...   ...     ...   \n",
       "253675                   0.0     1.0       1.0        1.0  45.0     0.0   \n",
       "253676                   0.0     1.0       1.0        1.0  18.0     0.0   \n",
       "253677                   0.0     0.0       0.0        1.0  28.0     0.0   \n",
       "253678                   0.0     1.0       0.0        1.0  23.0     0.0   \n",
       "253679                   1.0     1.0       1.0        1.0  25.0     0.0   \n",
       "\n",
       "        Stroke  Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0          0.0       0.0           0.0     0.0  ...            1.0   \n",
       "1          0.0       0.0           1.0     0.0  ...            0.0   \n",
       "2          0.0       0.0           0.0     1.0  ...            1.0   \n",
       "3          0.0       0.0           1.0     1.0  ...            1.0   \n",
       "4          0.0       0.0           1.0     1.0  ...            1.0   \n",
       "...        ...       ...           ...     ...  ...            ...   \n",
       "253675     0.0       0.0           0.0     1.0  ...            1.0   \n",
       "253676     0.0       2.0           0.0     0.0  ...            1.0   \n",
       "253677     0.0       0.0           1.0     1.0  ...            1.0   \n",
       "253678     0.0       0.0           0.0     1.0  ...            1.0   \n",
       "253679     0.0       2.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n",
       "1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n",
       "2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n",
       "3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n",
       "4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n",
       "...             ...      ...       ...       ...       ...  ...   ...   \n",
       "253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n",
       "253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n",
       "253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n",
       "253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "        Education  Income  \n",
       "0             4.0     3.0  \n",
       "1             6.0     1.0  \n",
       "2             4.0     8.0  \n",
       "3             3.0     6.0  \n",
       "4             5.0     4.0  \n",
       "...           ...     ...  \n",
       "253675        6.0     7.0  \n",
       "253676        2.0     4.0  \n",
       "253677        5.0     2.0  \n",
       "253678        5.0     1.0  \n",
       "253679        6.0     2.0  \n",
       "\n",
       "[253680 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart_disease_health_indicators_BRFSS2015.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compruebo valores unicos de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeartDiseaseorAttack\n",
      " [0. 1.]\n",
      "\n",
      "HighBP\n",
      " [1. 0.]\n",
      "\n",
      "HighChol\n",
      " [1. 0.]\n",
      "\n",
      "CholCheck\n",
      " [1. 0.]\n",
      "\n",
      "BMI\n",
      " [40. 25. 28. 27. 24. 30. 34. 26. 33. 21. 23. 22. 38. 32. 37. 31. 29. 20.\n",
      " 35. 45. 39. 19. 47. 18. 36. 43. 55. 49. 42. 17. 16. 41. 44. 50. 59. 48.\n",
      " 52. 46. 54. 57. 53. 14. 15. 51. 58. 63. 61. 56. 74. 62. 64. 66. 73. 85.\n",
      " 60. 67. 65. 70. 82. 79. 92. 68. 72. 88. 96. 13. 81. 71. 75. 12. 77. 69.\n",
      " 76. 87. 89. 84. 95. 98. 91. 86. 83. 80. 90. 78.]\n",
      "\n",
      "Smoker\n",
      " [1. 0.]\n",
      "\n",
      "Stroke\n",
      " [0. 1.]\n",
      "\n",
      "Diabetes\n",
      " [0. 2. 1.]\n",
      "\n",
      "PhysActivity\n",
      " [0. 1.]\n",
      "\n",
      "Fruits\n",
      " [0. 1.]\n",
      "\n",
      "Veggies\n",
      " [1. 0.]\n",
      "\n",
      "HvyAlcoholConsump\n",
      " [0. 1.]\n",
      "\n",
      "AnyHealthcare\n",
      " [1. 0.]\n",
      "\n",
      "NoDocbcCost\n",
      " [0. 1.]\n",
      "\n",
      "GenHlth\n",
      " [5. 3. 2. 4. 1.]\n",
      "\n",
      "MentHlth\n",
      " [18.  0. 30.  3.  5. 15. 10.  6. 20.  2. 25.  1.  4.  7.  8. 21. 14. 26.\n",
      " 29. 16. 28. 11. 12. 24. 17. 13. 27. 19. 22.  9. 23.]\n",
      "\n",
      "PhysHlth\n",
      " [15.  0. 30.  2. 14. 28.  7. 20.  3. 10.  1.  5. 17.  4. 19.  6. 12. 25.\n",
      " 27. 21. 22.  8. 29. 24.  9. 16. 18. 23. 13. 26. 11.]\n",
      "\n",
      "DiffWalk\n",
      " [1. 0.]\n",
      "\n",
      "Sex\n",
      " [0. 1.]\n",
      "\n",
      "Age\n",
      " [ 9.  7. 11. 10.  8. 13.  4.  6.  2. 12.  5.  1.  3.]\n",
      "\n",
      "Education\n",
      " [4. 6. 3. 5. 2. 1.]\n",
      "\n",
      "Income\n",
      " [3. 1. 8. 6. 4. 7. 2. 5.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in df:\n",
    "    print(f'{df.columns[x]}\\n {df[i].unique()}\\n')\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compruebo valores nulos de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartDiseaseorAttack    0\n",
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "BMI                     0\n",
       "Smoker                  0\n",
       "Stroke                  0\n",
       "Diabetes                0\n",
       "PhysActivity            0\n",
       "Fruits                  0\n",
       "Veggies                 0\n",
       "HvyAlcoholConsump       0\n",
       "AnyHealthcare           0\n",
       "NoDocbcCost             0\n",
       "GenHlth                 0\n",
       "MentHlth                0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Sex                     0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['HeartDiseaseorAttack'], axis=1)\n",
    "y = df['HeartDiseaseorAttack']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train: (202944, 21)\n",
      "Columnas de X_train: ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forma de X_train: {X_train.shape}\")\n",
    "print(f\"Columnas de X_train: {X_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Especificidad(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"especificidad\", **kwargs):\n",
    "        super(Especificidad, self).__init__(name=name, **kwargs)\n",
    "        self.true_negatives = self.add_weight(name=\"tn\", initializer=\"zeros\")\n",
    "        self.false_positives = self.add_weight(name=\"fp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convertir a float32 para evitar conflictos de tipo\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.round(y_pred)\n",
    "        tn = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_positives.assign_add(fp)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_negatives / (self.true_negatives + self.false_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_negatives.assign(0.0)\n",
    "        self.false_positives.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sensibilidad(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"sensibilidad\", **kwargs):\n",
    "        super(Sensibilidad, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n",
    "        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convertir a float32 para evitar conflictos de tipo\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.round(y_pred)  # Redondeamos para obtener las predicciones binarias\n",
    "        tp = tf.reduce_sum(y_true * y_pred)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=21))\n",
    "model.add(BatchNormalization())  # Normaliza entradas para mejor estabilidad\n",
    "model.add(Dropout(0.3))  # Evita sobreajuste\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Optimización con tasa de aprendizaje ajustada\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - Recall: 0.0711 - auc: 0.7438 - loss: 0.3219 - precision: 0.1603 - val_Recall: 0.0382 - val_auc: 0.8452 - val_loss: 0.2404 - val_precision: 0.6642\n",
      "Epoch 2/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0241 - auc: 0.8292 - loss: 0.2474 - precision: 0.5203 - val_Recall: 0.0405 - val_auc: 0.8479 - val_loss: 0.2429 - val_precision: 0.6498\n",
      "Epoch 3/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0295 - auc: 0.8366 - loss: 0.2435 - precision: 0.5346 - val_Recall: 0.0206 - val_auc: 0.8474 - val_loss: 0.2377 - val_precision: 0.7481\n",
      "Epoch 4/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0313 - auc: 0.8369 - loss: 0.2429 - precision: 0.5042 - val_Recall: 0.1227 - val_auc: 0.8453 - val_loss: 0.2391 - val_precision: 0.5342\n",
      "Epoch 5/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0332 - auc: 0.8345 - loss: 0.2448 - precision: 0.5246 - val_Recall: 0.0432 - val_auc: 0.8479 - val_loss: 0.2383 - val_precision: 0.6624\n",
      "Epoch 6/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0360 - auc: 0.8387 - loss: 0.2407 - precision: 0.5135 - val_Recall: 0.0717 - val_auc: 0.8473 - val_loss: 0.2371 - val_precision: 0.6173\n",
      "Epoch 7/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0471 - auc: 0.8407 - loss: 0.2419 - precision: 0.5528 - val_Recall: 0.0166 - val_auc: 0.8483 - val_loss: 0.2373 - val_precision: 0.7596\n",
      "Epoch 8/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0217 - auc: 0.8357 - loss: 0.2425 - precision: 0.5692 - val_Recall: 0.0594 - val_auc: 0.8486 - val_loss: 0.2373 - val_precision: 0.6193\n",
      "Epoch 9/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0433 - auc: 0.8394 - loss: 0.2405 - precision: 0.5361 - val_Recall: 0.0164 - val_auc: 0.8472 - val_loss: 0.2392 - val_precision: 0.7290\n",
      "Epoch 10/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0461 - auc: 0.8409 - loss: 0.2417 - precision: 0.5334 - val_Recall: 0.0359 - val_auc: 0.8479 - val_loss: 0.2381 - val_precision: 0.6980\n",
      "Epoch 11/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0444 - auc: 0.8386 - loss: 0.2426 - precision: 0.5116 - val_Recall: 0.0449 - val_auc: 0.8481 - val_loss: 0.2369 - val_precision: 0.6524\n",
      "Epoch 12/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0386 - auc: 0.8371 - loss: 0.2428 - precision: 0.5342 - val_Recall: 0.0581 - val_auc: 0.8481 - val_loss: 0.2385 - val_precision: 0.6048\n",
      "Epoch 13/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0436 - auc: 0.8379 - loss: 0.2422 - precision: 0.5395 - val_Recall: 0.0799 - val_auc: 0.8477 - val_loss: 0.2373 - val_precision: 0.5944\n",
      "Epoch 14/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0442 - auc: 0.8408 - loss: 0.2407 - precision: 0.5353 - val_Recall: 0.0487 - val_auc: 0.8481 - val_loss: 0.2368 - val_precision: 0.6270\n",
      "Epoch 15/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0574 - auc: 0.8388 - loss: 0.2431 - precision: 0.5731 - val_Recall: 0.0734 - val_auc: 0.8487 - val_loss: 0.2363 - val_precision: 0.6034\n",
      "Epoch 16/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0542 - auc: 0.8402 - loss: 0.2406 - precision: 0.5672 - val_Recall: 0.0805 - val_auc: 0.8482 - val_loss: 0.2366 - val_precision: 0.5953\n",
      "Epoch 17/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0520 - auc: 0.8389 - loss: 0.2408 - precision: 0.5536 - val_Recall: 0.0285 - val_auc: 0.8485 - val_loss: 0.2371 - val_precision: 0.7047\n",
      "Epoch 18/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0552 - auc: 0.8417 - loss: 0.2421 - precision: 0.5281 - val_Recall: 0.0401 - val_auc: 0.8485 - val_loss: 0.2369 - val_precision: 0.6497\n",
      "Epoch 19/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0528 - auc: 0.8400 - loss: 0.2416 - precision: 0.5447 - val_Recall: 0.0302 - val_auc: 0.8481 - val_loss: 0.2372 - val_precision: 0.6857\n",
      "Epoch 20/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0525 - auc: 0.8396 - loss: 0.2427 - precision: 0.5695 - val_Recall: 0.0682 - val_auc: 0.8482 - val_loss: 0.2368 - val_precision: 0.5752\n",
      "Epoch 21/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0546 - auc: 0.8394 - loss: 0.2417 - precision: 0.5482 - val_Recall: 0.0493 - val_auc: 0.8484 - val_loss: 0.2382 - val_precision: 0.6267\n",
      "Epoch 22/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0540 - auc: 0.8379 - loss: 0.2440 - precision: 0.5406 - val_Recall: 0.0258 - val_auc: 0.8481 - val_loss: 0.2375 - val_precision: 0.7151\n",
      "Epoch 23/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0470 - auc: 0.8408 - loss: 0.2411 - precision: 0.5459 - val_Recall: 0.0388 - val_auc: 0.8481 - val_loss: 0.2372 - val_precision: 0.6584\n",
      "Epoch 24/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0559 - auc: 0.8394 - loss: 0.2417 - precision: 0.5727 - val_Recall: 0.0914 - val_auc: 0.8479 - val_loss: 0.2367 - val_precision: 0.5699\n",
      "Epoch 25/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0647 - auc: 0.8404 - loss: 0.2410 - precision: 0.5766 - val_Recall: 0.0797 - val_auc: 0.8476 - val_loss: 0.2373 - val_precision: 0.5947\n",
      "Epoch 26/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0573 - auc: 0.8389 - loss: 0.2436 - precision: 0.5566 - val_Recall: 0.0797 - val_auc: 0.8472 - val_loss: 0.2374 - val_precision: 0.5873\n",
      "Epoch 27/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0625 - auc: 0.8404 - loss: 0.2438 - precision: 0.5227 - val_Recall: 0.0516 - val_auc: 0.8480 - val_loss: 0.2370 - val_precision: 0.6276\n",
      "Epoch 28/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0491 - auc: 0.8397 - loss: 0.2423 - precision: 0.5465 - val_Recall: 0.1055 - val_auc: 0.8476 - val_loss: 0.2370 - val_precision: 0.5703\n",
      "Epoch 29/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0542 - auc: 0.8407 - loss: 0.2408 - precision: 0.5527 - val_Recall: 0.0858 - val_auc: 0.8482 - val_loss: 0.2366 - val_precision: 0.5919\n",
      "Epoch 30/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0611 - auc: 0.8381 - loss: 0.2432 - precision: 0.5487 - val_Recall: 0.0766 - val_auc: 0.8481 - val_loss: 0.2367 - val_precision: 0.5935\n",
      "Epoch 31/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0533 - auc: 0.8397 - loss: 0.2416 - precision: 0.5493 - val_Recall: 0.0562 - val_auc: 0.8485 - val_loss: 0.2366 - val_precision: 0.6321\n",
      "Epoch 32/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0514 - auc: 0.8415 - loss: 0.2401 - precision: 0.5265 - val_Recall: 0.1072 - val_auc: 0.8476 - val_loss: 0.2379 - val_precision: 0.5622\n",
      "Epoch 33/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0628 - auc: 0.8414 - loss: 0.2410 - precision: 0.5584 - val_Recall: 0.0340 - val_auc: 0.8484 - val_loss: 0.2376 - val_precision: 0.6835\n",
      "Epoch 34/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0662 - auc: 0.8429 - loss: 0.2403 - precision: 0.5686 - val_Recall: 0.0497 - val_auc: 0.8480 - val_loss: 0.2371 - val_precision: 0.6458\n",
      "Epoch 35/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0608 - auc: 0.8421 - loss: 0.2396 - precision: 0.5575 - val_Recall: 0.0684 - val_auc: 0.8482 - val_loss: 0.2370 - val_precision: 0.5874\n",
      "Epoch 36/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0623 - auc: 0.8399 - loss: 0.2423 - precision: 0.5619 - val_Recall: 0.0472 - val_auc: 0.8483 - val_loss: 0.2374 - val_precision: 0.6392\n",
      "Epoch 37/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0550 - auc: 0.8423 - loss: 0.2383 - precision: 0.5740 - val_Recall: 0.0445 - val_auc: 0.8483 - val_loss: 0.2370 - val_precision: 0.6199\n",
      "Epoch 38/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0695 - auc: 0.8416 - loss: 0.2409 - precision: 0.5579 - val_Recall: 0.1023 - val_auc: 0.8487 - val_loss: 0.2368 - val_precision: 0.5708\n",
      "Epoch 39/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0670 - auc: 0.8414 - loss: 0.2402 - precision: 0.5583 - val_Recall: 0.1099 - val_auc: 0.8488 - val_loss: 0.2382 - val_precision: 0.5487\n",
      "Epoch 40/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0583 - auc: 0.8412 - loss: 0.2409 - precision: 0.5356 - val_Recall: 0.0786 - val_auc: 0.8484 - val_loss: 0.2366 - val_precision: 0.5878\n",
      "Epoch 41/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0441 - auc: 0.8381 - loss: 0.2416 - precision: 0.5180 - val_Recall: 0.0935 - val_auc: 0.8487 - val_loss: 0.2366 - val_precision: 0.5733\n",
      "Epoch 42/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0601 - auc: 0.8414 - loss: 0.2415 - precision: 0.5453 - val_Recall: 0.1116 - val_auc: 0.8485 - val_loss: 0.2379 - val_precision: 0.5542\n",
      "Epoch 43/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0573 - auc: 0.8397 - loss: 0.2433 - precision: 0.5464 - val_Recall: 0.1028 - val_auc: 0.8481 - val_loss: 0.2366 - val_precision: 0.5652\n",
      "Epoch 44/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0627 - auc: 0.8411 - loss: 0.2411 - precision: 0.5437 - val_Recall: 0.0478 - val_auc: 0.8480 - val_loss: 0.2374 - val_precision: 0.6196\n",
      "Epoch 45/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0648 - auc: 0.8436 - loss: 0.2395 - precision: 0.5642 - val_Recall: 0.0633 - val_auc: 0.8486 - val_loss: 0.2366 - val_precision: 0.5980\n",
      "Epoch 46/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0591 - auc: 0.8414 - loss: 0.2396 - precision: 0.5615 - val_Recall: 0.0665 - val_auc: 0.8482 - val_loss: 0.2370 - val_precision: 0.6038\n",
      "Epoch 47/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0530 - auc: 0.8412 - loss: 0.2397 - precision: 0.5238 - val_Recall: 0.0768 - val_auc: 0.8485 - val_loss: 0.2366 - val_precision: 0.5980\n",
      "Epoch 48/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0582 - auc: 0.8416 - loss: 0.2418 - precision: 0.5348 - val_Recall: 0.0789 - val_auc: 0.8487 - val_loss: 0.2366 - val_precision: 0.5959\n",
      "Epoch 49/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0644 - auc: 0.8400 - loss: 0.2419 - precision: 0.5608 - val_Recall: 0.0575 - val_auc: 0.8484 - val_loss: 0.2373 - val_precision: 0.6185\n",
      "Epoch 50/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0595 - auc: 0.8403 - loss: 0.2426 - precision: 0.5421 - val_Recall: 0.0726 - val_auc: 0.8479 - val_loss: 0.2369 - val_precision: 0.5935\n",
      "Epoch 51/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0636 - auc: 0.8425 - loss: 0.2417 - precision: 0.5727 - val_Recall: 0.0766 - val_auc: 0.8486 - val_loss: 0.2368 - val_precision: 0.5897\n",
      "Epoch 52/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0488 - auc: 0.8403 - loss: 0.2419 - precision: 0.5267 - val_Recall: 0.0904 - val_auc: 0.8485 - val_loss: 0.2365 - val_precision: 0.5770\n",
      "Epoch 53/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0589 - auc: 0.8428 - loss: 0.2419 - precision: 0.5569 - val_Recall: 0.0770 - val_auc: 0.8487 - val_loss: 0.2365 - val_precision: 0.6007\n",
      "Epoch 54/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0627 - auc: 0.8419 - loss: 0.2406 - precision: 0.5567 - val_Recall: 0.0734 - val_auc: 0.8484 - val_loss: 0.2370 - val_precision: 0.5882\n",
      "Epoch 55/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0526 - auc: 0.8409 - loss: 0.2413 - precision: 0.5331 - val_Recall: 0.1128 - val_auc: 0.8486 - val_loss: 0.2364 - val_precision: 0.5598\n",
      "Epoch 56/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0695 - auc: 0.8427 - loss: 0.2390 - precision: 0.5625 - val_Recall: 0.1623 - val_auc: 0.8480 - val_loss: 0.2399 - val_precision: 0.5320\n",
      "Epoch 57/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0728 - auc: 0.8421 - loss: 0.2411 - precision: 0.5533 - val_Recall: 0.1019 - val_auc: 0.8477 - val_loss: 0.2373 - val_precision: 0.5664\n",
      "Epoch 58/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0698 - auc: 0.8439 - loss: 0.2405 - precision: 0.5672 - val_Recall: 0.0759 - val_auc: 0.8485 - val_loss: 0.2369 - val_precision: 0.5944\n",
      "Epoch 59/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0655 - auc: 0.8414 - loss: 0.2408 - precision: 0.5623 - val_Recall: 0.0673 - val_auc: 0.8484 - val_loss: 0.2366 - val_precision: 0.5944\n",
      "Epoch 60/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0580 - auc: 0.8401 - loss: 0.2418 - precision: 0.5582 - val_Recall: 0.0948 - val_auc: 0.8475 - val_loss: 0.2372 - val_precision: 0.5729\n",
      "Epoch 61/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0632 - auc: 0.8426 - loss: 0.2408 - precision: 0.5481 - val_Recall: 0.1055 - val_auc: 0.8482 - val_loss: 0.2366 - val_precision: 0.5645\n",
      "Epoch 62/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0658 - auc: 0.8422 - loss: 0.2424 - precision: 0.5356 - val_Recall: 0.0195 - val_auc: 0.8486 - val_loss: 0.2372 - val_precision: 0.7154\n",
      "Epoch 63/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0580 - auc: 0.8411 - loss: 0.2398 - precision: 0.5512 - val_Recall: 0.0638 - val_auc: 0.8481 - val_loss: 0.2367 - val_precision: 0.6154\n",
      "Epoch 64/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0562 - auc: 0.8414 - loss: 0.2378 - precision: 0.5620 - val_Recall: 0.0474 - val_auc: 0.8484 - val_loss: 0.2369 - val_precision: 0.6260\n",
      "Epoch 65/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0573 - auc: 0.8410 - loss: 0.2416 - precision: 0.5634 - val_Recall: 0.0791 - val_auc: 0.8477 - val_loss: 0.2370 - val_precision: 0.5984\n",
      "Epoch 66/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0591 - auc: 0.8394 - loss: 0.2411 - precision: 0.5605 - val_Recall: 0.0648 - val_auc: 0.8483 - val_loss: 0.2374 - val_precision: 0.6119\n",
      "Epoch 67/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0627 - auc: 0.8428 - loss: 0.2401 - precision: 0.5385 - val_Recall: 0.1164 - val_auc: 0.8483 - val_loss: 0.2366 - val_precision: 0.5595\n",
      "Epoch 68/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0712 - auc: 0.8439 - loss: 0.2390 - precision: 0.5576 - val_Recall: 0.0740 - val_auc: 0.8486 - val_loss: 0.2366 - val_precision: 0.5963\n",
      "Epoch 69/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0627 - auc: 0.8426 - loss: 0.2395 - precision: 0.5462 - val_Recall: 0.0675 - val_auc: 0.8484 - val_loss: 0.2368 - val_precision: 0.6019\n",
      "Epoch 70/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0621 - auc: 0.8407 - loss: 0.2414 - precision: 0.5597 - val_Recall: 0.0717 - val_auc: 0.8489 - val_loss: 0.2367 - val_precision: 0.5948\n",
      "Epoch 71/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0608 - auc: 0.8422 - loss: 0.2395 - precision: 0.5511 - val_Recall: 0.0759 - val_auc: 0.8486 - val_loss: 0.2364 - val_precision: 0.5964\n",
      "Epoch 72/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0604 - auc: 0.8413 - loss: 0.2408 - precision: 0.5628 - val_Recall: 0.0526 - val_auc: 0.8483 - val_loss: 0.2378 - val_precision: 0.6137\n",
      "Epoch 73/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0683 - auc: 0.8432 - loss: 0.2391 - precision: 0.5513 - val_Recall: 0.0392 - val_auc: 0.8481 - val_loss: 0.2369 - val_precision: 0.6631\n",
      "Epoch 74/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0561 - auc: 0.8392 - loss: 0.2429 - precision: 0.5659 - val_Recall: 0.0661 - val_auc: 0.8487 - val_loss: 0.2379 - val_precision: 0.6081\n",
      "Epoch 75/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0623 - auc: 0.8417 - loss: 0.2413 - precision: 0.5613 - val_Recall: 0.0761 - val_auc: 0.8485 - val_loss: 0.2368 - val_precision: 0.5912\n",
      "Epoch 76/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0660 - auc: 0.8422 - loss: 0.2418 - precision: 0.5497 - val_Recall: 0.0975 - val_auc: 0.8484 - val_loss: 0.2365 - val_precision: 0.5643\n",
      "Epoch 77/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0622 - auc: 0.8410 - loss: 0.2409 - precision: 0.5550 - val_Recall: 0.0728 - val_auc: 0.8483 - val_loss: 0.2365 - val_precision: 0.5942\n",
      "Epoch 78/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0507 - auc: 0.8410 - loss: 0.2418 - precision: 0.5198 - val_Recall: 0.1141 - val_auc: 0.8481 - val_loss: 0.2367 - val_precision: 0.5597\n",
      "Epoch 79/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0748 - auc: 0.8439 - loss: 0.2399 - precision: 0.5525 - val_Recall: 0.0562 - val_auc: 0.8482 - val_loss: 0.2367 - val_precision: 0.6276\n",
      "Epoch 80/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0615 - auc: 0.8450 - loss: 0.2391 - precision: 0.5601 - val_Recall: 0.0952 - val_auc: 0.8481 - val_loss: 0.2377 - val_precision: 0.5711\n",
      "Epoch 81/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0702 - auc: 0.8386 - loss: 0.2422 - precision: 0.5534 - val_Recall: 0.0625 - val_auc: 0.8484 - val_loss: 0.2368 - val_precision: 0.6045\n",
      "Epoch 82/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0646 - auc: 0.8415 - loss: 0.2415 - precision: 0.5535 - val_Recall: 0.0520 - val_auc: 0.8480 - val_loss: 0.2372 - val_precision: 0.6169\n",
      "Epoch 83/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0604 - auc: 0.8419 - loss: 0.2390 - precision: 0.5476 - val_Recall: 0.0791 - val_auc: 0.8485 - val_loss: 0.2366 - val_precision: 0.5872\n",
      "Epoch 84/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0650 - auc: 0.8421 - loss: 0.2416 - precision: 0.5550 - val_Recall: 0.0740 - val_auc: 0.8478 - val_loss: 0.2374 - val_precision: 0.5913\n",
      "Epoch 85/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0680 - auc: 0.8418 - loss: 0.2401 - precision: 0.5779 - val_Recall: 0.0591 - val_auc: 0.8483 - val_loss: 0.2368 - val_precision: 0.6184\n",
      "Epoch 86/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0592 - auc: 0.8449 - loss: 0.2397 - precision: 0.5336 - val_Recall: 0.1126 - val_auc: 0.8484 - val_loss: 0.2366 - val_precision: 0.5576\n",
      "Epoch 87/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0654 - auc: 0.8428 - loss: 0.2399 - precision: 0.5265 - val_Recall: 0.0856 - val_auc: 0.8478 - val_loss: 0.2374 - val_precision: 0.5845\n",
      "Epoch 88/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0594 - auc: 0.8418 - loss: 0.2394 - precision: 0.5258 - val_Recall: 0.0554 - val_auc: 0.8485 - val_loss: 0.2375 - val_precision: 0.6286\n",
      "Epoch 89/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0680 - auc: 0.8419 - loss: 0.2429 - precision: 0.5729 - val_Recall: 0.0812 - val_auc: 0.8480 - val_loss: 0.2372 - val_precision: 0.5972\n",
      "Epoch 90/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0627 - auc: 0.8424 - loss: 0.2402 - precision: 0.5601 - val_Recall: 0.0394 - val_auc: 0.8485 - val_loss: 0.2369 - val_precision: 0.6643\n",
      "Epoch 91/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0569 - auc: 0.8413 - loss: 0.2406 - precision: 0.5282 - val_Recall: 0.0669 - val_auc: 0.8487 - val_loss: 0.2385 - val_precision: 0.6030\n",
      "Epoch 92/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0606 - auc: 0.8428 - loss: 0.2401 - precision: 0.5587 - val_Recall: 0.0747 - val_auc: 0.8489 - val_loss: 0.2367 - val_precision: 0.5983\n",
      "Epoch 93/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0695 - auc: 0.8428 - loss: 0.2419 - precision: 0.5538 - val_Recall: 0.0810 - val_auc: 0.8485 - val_loss: 0.2367 - val_precision: 0.5984\n",
      "Epoch 94/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0516 - auc: 0.8388 - loss: 0.2418 - precision: 0.5350 - val_Recall: 0.0889 - val_auc: 0.8487 - val_loss: 0.2369 - val_precision: 0.5864\n",
      "Epoch 95/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0626 - auc: 0.8411 - loss: 0.2409 - precision: 0.5576 - val_Recall: 0.0482 - val_auc: 0.8481 - val_loss: 0.2368 - val_precision: 0.6571\n",
      "Epoch 96/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0604 - auc: 0.8419 - loss: 0.2393 - precision: 0.5636 - val_Recall: 0.0686 - val_auc: 0.8486 - val_loss: 0.2371 - val_precision: 0.6011\n",
      "Epoch 97/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0593 - auc: 0.8407 - loss: 0.2413 - precision: 0.5389 - val_Recall: 0.0799 - val_auc: 0.8479 - val_loss: 0.2366 - val_precision: 0.5972\n",
      "Epoch 98/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0579 - auc: 0.8416 - loss: 0.2406 - precision: 0.5390 - val_Recall: 0.0461 - val_auc: 0.8485 - val_loss: 0.2368 - val_precision: 0.6304\n",
      "Epoch 99/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0581 - auc: 0.8434 - loss: 0.2389 - precision: 0.5355 - val_Recall: 0.0642 - val_auc: 0.8487 - val_loss: 0.2366 - val_precision: 0.6012\n",
      "Epoch 100/100\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - Recall: 0.0661 - auc: 0.8442 - loss: 0.2410 - precision: 0.5656 - val_Recall: 0.0673 - val_auc: 0.8480 - val_loss: 0.2368 - val_precision: 0.6057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cabbf7eea0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443us/step\n",
      "{'TP': np.int64(4264), 'FP': np.int64(17326), 'TN': np.int64(28642), 'FN': np.int64(504)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#x_test = x\n",
    "#y_test = y # y_true\n",
    "\n",
    "def get_matriz_confusion(y_true, y_score, threshold=0.05):\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    return {\"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN}\n",
    "\n",
    "y_score = model.predict(X_test).ravel()  # Convierte un array multidimensional en un vector unidimensional\n",
    "matriz_conf = get_matriz_confusion(y_test, y_score)\n",
    "print(matriz_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_matriz_confusion(ax, matriz_conf['TP'], matriz_conf['TN'], matriz_conf['FP'], matriz_conf['FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
